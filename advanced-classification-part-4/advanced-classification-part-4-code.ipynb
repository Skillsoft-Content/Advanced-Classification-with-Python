{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386fc0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## ADVANCED CLASSIFICATION PART 4/ADVANCED CLASSIFICATION PART 4 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd61cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 2: Loading packages  ####\n",
    "\n",
    "# Helper packages.\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt                     \n",
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "# Scikit-learn packages for building models and model evaluation.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 7: Directory settings  ####\n",
    "\n",
    "# Set 'main_dir' to location of the project folder\n",
    "home_dir = Path(\".\").resolve()\n",
    "main_dir = home_dir.parent.parent\n",
    "print(main_dir)\n",
    "data_dir = str(main_dir) + \"/data\"\n",
    "print(data_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2c71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 8: Load the cleaned dataset and model metrics   ####\n",
    "\n",
    "costa_clean = pickle.load(open(data_dir + \"/costa_clean.sav\",\"rb\"))\n",
    "metrics_gbm = pickle.load(open(data_dir + \"/metrics_forest.sav\",\"rb\"))\n",
    "print(costa_clean.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 9: Print info for our data  ####\n",
    "\n",
    "costa_clean.columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b47651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 10: Split into training and test sets  ####\n",
    "\n",
    "# Select the predictors and target.\n",
    "X = costa_clean.drop(['Target'], axis = 1)\n",
    "y = np.array(costa_clean['Target'])\n",
    "\n",
    "# Set the seed to 1.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Split into training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 11: Vanilla GBM model  ####\n",
    "\n",
    "# Initialize GBM model.\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model to train data.\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 12: Convenience function for performance metrics  ####\n",
    "\n",
    "def get_performance_scores(y_test, y_predict, y_predict_prob, eps=1e-15, beta=0.5):\n",
    "    from sklearn import metrics\n",
    "    # Scores keys.\n",
    "    metric_keys = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"fbeta\", \"log_loss\", \"AUC\"]\n",
    "    # Score values.\n",
    "    metric_values = [None]*len(metric_keys)\n",
    "    metric_values[0] = metrics.accuracy_score(y_test, y_predict)\n",
    "    metric_values[1] = metrics.precision_score(y_test, y_predict)\n",
    "    metric_values[2] = metrics.recall_score(y_test, y_predict)\n",
    "    metric_values[3] = metrics.f1_score(y_test, y_predict)\n",
    "    metric_values[4] = metrics.fbeta_score(y_test, y_predict, beta=beta)\n",
    "    metric_values[5] = metrics.log_loss(y_test, y_predict_prob[:, 1], eps=eps)\n",
    "    metric_values[6] = metrics.roc_auc_score(y_test, y_predict_prob[:, 1])\n",
    "    perf_metrics = dict(zip(metric_keys, metric_values))\n",
    "    return(perf_metrics)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec291dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 13: Predict and evaluate vanilla GBM model  ####\n",
    "\n",
    "# Predict on test data for GBM model.\n",
    "gbm_y_predict = gbm.predict(X_test)\n",
    "\n",
    "# Get prediction probabilities for the GBM model.\n",
    "gbm_y_predict_proba = gbm.predict_proba(X_test)\n",
    "\n",
    "# Get the GBM performance scores.\n",
    "gbm_scores = get_performance_scores(y_test, gbm_y_predict, gbm_y_predict_proba)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 14: Precision vs recall curve: the tradeoff  ####\n",
    "\n",
    "ax = plt.gca()\n",
    "gbm_prec_recall = metrics.plot_precision_recall_curve(gbm, \n",
    "                                    X_test, \n",
    "                                    y_test,\n",
    "                                    ax = ax,\n",
    "                                    name = \"GBM\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18721f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 15: ROC curve: the tradeoff  ####\n",
    "\n",
    "ax = plt.gca()\n",
    "gbm_roc = metrics.plot_roc_curve(gbm, \n",
    "                                 X_test, \n",
    "                                 y_test,\n",
    "                                 ax = ax,\n",
    "                                 name = \"GBM\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 16: Append to other model performance scores   ####\n",
    "\n",
    "metrics_gbm.update({\"GBM\": gbm_scores})\n",
    "print(metrics_gbm)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 19: Randomized CV for GBM optimization: parameters  ####\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "# Number of trees in random forest.\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 20)]\n",
    "# Number of features to consider at every split.\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree.\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node.\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node.\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Define learning rate parameters.\n",
    "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b148a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 20: Randomized CV for GBM optimization: create grid  ####\n",
    "\n",
    "# Create the random grid.\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'learning_rate': learning_rate}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a42b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 21: Randomized CV for GBM optimization: fit  ####\n",
    "\n",
    "# Initialize the randomized search model just as you would any other scikit model.\n",
    "gbm_random = RandomizedSearchCV(estimator = gbm, \n",
    "                                param_distributions = random_grid, \n",
    "                                n_iter = 100, \n",
    "                                cv = 3, \n",
    "                                verbose = 0, \n",
    "                                random_state = 1, \n",
    "                                n_jobs = -1)\n",
    "                                \n",
    "# Fit the random search model.\n",
    "gbm_random.fit(X_train, y_train)\n",
    "gbm_random = pickle.load(open(data_dir + \"/gbm_random.sav\",\"rb\"))\n",
    "gbm_random.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 22: Implement optimized GBM model  ####\n",
    "\n",
    "# Pass parameters from randomized search to GBM classifier.\n",
    "optimized_gbm = GradientBoostingClassifier(**gbm_random.best_params_)\n",
    "\n",
    "# Fit model to train data.\n",
    "optimized_gbm.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf90773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 24: Exercise 1  ####\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 26: Predict and evaluate optimized GBM model  ####\n",
    "\n",
    "# Get class predictions.\n",
    "optimized_gbm_y_predict = optimized_gbm.predict(X_test)\n",
    "\n",
    "# Get prediction probabilities.\n",
    "optimized_gbm_y_predict_proba = optimized_gbm.predict_proba(X_test)\n",
    "\n",
    "# Compute performance metrics.\n",
    "optimized_gbm_scores = get_performance_scores(y_test, \n",
    "                                              optimized_gbm_y_predict, \n",
    "                                              optimized_gbm_y_predict_proba)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d17845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 27: Precision vs recall curve: the tradeoff  ####\n",
    "\n",
    "ax = plt.gca()\n",
    "opt_gbm_prec_recall = metrics.plot_precision_recall_curve(optimized_gbm, \n",
    "                                    X_test, \n",
    "                                    y_test,\n",
    "                                    ax = ax,\n",
    "                                    name = \"Optimized GBM\")\n",
    "\n",
    "gbm_prec_recall.plot(ax = ax, name = \"GBM\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade29656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 28: ROC curve: the tradeoff  ####\n",
    "\n",
    "ax = plt.gca()\n",
    "opt_gbm_roc = metrics.plot_roc_curve(optimized_gbm, \n",
    "                                     X_test, \n",
    "                                     y_test,\n",
    "                                     ax = ax,\n",
    "                                     name = \"Optimized GBM\")\n",
    "\n",
    "\n",
    "gbm_roc.plot(ax = ax, name = \"GBM\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd518d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 29: Append to other model performance scores   ####\n",
    "\n",
    "metrics_gbm.update({\"Optimized GBM\": optimized_gbm_scores})\n",
    "print(metrics_gbm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9a1cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 30: Convert metrics dictionary to dataframe  ####\n",
    "\n",
    "# Convert all metrics for each model to a dataframe.\n",
    "metrics_gbm_df = pd.DataFrame(metrics_gbm)\n",
    "metrics_gbm_df[\"metric\"] = metrics_gbm_df.index\n",
    "metrics_gbm_df = metrics_gbm_df.reset_index(drop = True)\n",
    "print(metrics_gbm_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8837584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 31: Convert wide to long format  ####\n",
    "\n",
    "metrics_gbm_long = pd.melt(metrics_gbm_df, \n",
    "                          id_vars = \"metric\",\n",
    "                          var_name = \"model\",\n",
    "                          value_vars = list(metrics_gbm.keys()))\n",
    "print(metrics_gbm_long.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15093600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 32: Plot all models by metric  ####\n",
    "\n",
    "# Create a 2X3 grid.\n",
    "fig, axes = plt.subplots(2, 3, figsize = (12, 6))\n",
    "# For each group in a grouped by metric dataframe, assign a metric to an axis object.\n",
    "for (metric, group), ax in zip(metrics_gbm_long.groupby(\"metric\"), axes.flatten()):\n",
    "    # Plot each metric as a bar plot.\n",
    "    group.plot(x = 'model',                                #<- model on x-axis\n",
    "               y = 'value',                                #<- metric value on y-axis\n",
    "               kind = 'bar',                               #<- bar plot \n",
    "               color = [\"red\", \"green\", \"blue\", \"orange\"], #<- color for each model\n",
    "               ax = ax,                                    #<- axis object \n",
    "               title = metric,                             #<- plot title\n",
    "               legend = None,                              #<- remove auto-legend\n",
    "               sharex = True)                              #<- use the same x-axis\n",
    "    ax.xaxis.set_tick_params(rotation = 45, labelsize=10)                #<- rotate labels for prettiness\n",
    "plt.tight_layout(0.5)                                      #<- make sure no space is unused\n",
    "plt.show()              \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9291f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 34: Wrap comparison plot into a function  ####\n",
    "\n",
    "def compare_metrics(metrics_dict, color_list = None):\n",
    "    metrics_df = pd.DataFrame(metrics_dict)\n",
    "    metrics_df[\"metric\"] = metrics_df.index\n",
    "    metrics_df = metrics_df.reset_index(drop = True)\n",
    "    metrics_long = pd.melt(metrics_df, id_vars = \"metric\", var_name = \"model\",\n",
    "                           value_vars = list(metrics_dict.keys()))\n",
    "    if color_list is None:\n",
    "        cmap = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "        colors = cmap[:len(metrics_dict.keys())]\n",
    "    else:\n",
    "        colors = color_list\n",
    "    fig, axes = plt.subplots(2, 3, figsize = (12, 6))\n",
    "    for (metric, group), ax in zip(metrics_long.groupby(\"metric\"), axes.flatten()):\n",
    "        group.plot(x = 'model', y = 'value', kind = 'bar', color = colors, ax = ax,\n",
    "                   title = metric,legend = None,sharex = True)\n",
    "        ax.xaxis.set_tick_params(rotation = 45, labelsize=10)\n",
    "    plt.tight_layout(0.5)\n",
    "    return((fig, axes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c0ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 35: Test function  ####\n",
    "\n",
    "fig, axes = compare_metrics(metrics_gbm)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
